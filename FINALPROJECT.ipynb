{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Submission for Unit 1 Project\n",
    "#### Group 8: Annaston Evers, Juliette Vasquez, Madison Gaines, Mrityunjay Sivakumar, Shirley Lin, Uday Thakar, Victor Irby\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code and Resulting Visualization\n",
    "Below is the Python code for the following models:\n",
    "1. **Integrate and Fire (IF) Neuron Model**\n",
    "2. **Leaky Integrate and Fire (LIF) Model**\n",
    "3. **Simple Feedforward Neural Network (FNN)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate and Fire Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Parameters\n",
                "V_rest = -65  # Resting potential (mV)\n",
                "V_th = -55    # Threshold potential (mV)\n",
                "V_reset = V_rest  # Reset potential after firing (mV)\n",
                "tau = 20  # Membrane time constant (ms)\n",
                "R = 10  # Membrane resistance (MÎ©)\n",
                "dt = 0.1  # Time step (ms)\n",
                "T = 100  # Total time for the simulation (ms)\n",
                "\n",
                "# Function to simulate the pure integrate-and-fire model\n",
                "def integrate_and_fire(I_ext, T=100, dt=0.1):\n",
                "    # Initialize time and membrane potential arrays\n",
                "    t = np.arange(0, T, dt)\n",
                "    V = np.full_like(t, V_rest)  # Membrane potential (initially resting potential)\n",
                "\n",
                "    # Iterate over each time step\n",
                "    for i in range(1, len(t)):\n",
                "        # Update membrane potential without decay\n",
                "        dV = (R * I_ext) * dt / tau  # No leak term\n",
                "        V[i] = V[i-1] + dV\n",
                "\n",
                "        # Check if the potential exceeds the threshold\n",
                "        if V[i] >= V_th:\n",
                "            V[i] = V_reset  # Reset after firing\n",
                "\n",
                "    return t, V\n",
                "\n",
                "# Simulate with different input currents\n",
                "I_ext_low = 1.5  # Low input current (nA)\n",
                "I_ext_high = 3.0  # High input current (nA)\n",
                "\n",
                "# Get results for both currents\n",
                "t_low, V_low = integrate_and_fire(I_ext_low)\n",
                "t_high, V_high = integrate_and_fire(I_ext_high)\n",
                "\n",
                "# Plotting the results\n",
                "plt.figure(figsize=(10, 6))\n",
                "\n",
                "# Low current input\n",
                "plt.subplot(2, 1, 1)\n",
                "plt.plot(t_low, V_low, label=f'I_ext = {I_ext_low} nA')\n",
                "plt.axhline(y=V_th, color='r', linestyle='--', label=\"Threshold (-55 mV)\")\n",
                "plt.axhline(y=V_rest, color='g', linestyle='--', label=\"Resting Potential (-65 mV)\")\n",
                "plt.title('Firing Pattern with Low Input Current')\n",
                "plt.xlabel('Time (ms)')\n",
                "plt.ylabel('Membrane Potential (mV)')\n",
                "plt.legend(loc='upper right')\n",
                "\n",
                "# High current input\n",
                "plt.subplot(2, 1, 2)\n",
                "plt.plot(t_high, V_high, label=f'I_ext = {I_ext_high} nA', color='orange')\n",
                "plt.axhline(y=V_th, color='r', linestyle='--', label=\"Threshold (-55 mV)\")\n",
                "plt.axhline(y=V_rest, color='g', linestyle='--', label=\"Resting Potential (-65 mV)\")\n",
                "plt.title('Firing Pattern with High Input Current')\n",
                "plt.xlabel('Time(ms)')\n",
                "plt.ylabel('Membrane Potential(mV)')\n",
                "plt.legend(loc='upper right')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n"
            ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IF Model Results](IFModelGraph.png)\n"
   ]
  },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIF Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lif_model",
   "metadata": {},
   "outputs": [],
   "source": [

       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "\n",
       "# Hodgkin-Huxley Model Parameters\n",
       "V_rest = -65  # Resting potential (mV)\n",
       "C_m = 1.0  # Membrane capacitance (uF/cm^2)\n",
       "E_Na = 50  # Sodium reversal potential (mV)\n",
       "E_K = -77  # Potassium reversal potential (mV)\n",
       "E_L = -54.4  # Leak reversal potential (mV)\n",
       "G_Na = 120  # Sodium conductance (mS/cm^2)\n",
       "G_K = 36  # Potassium conductance (mS/cm^2)\n",
       "G_L = 0.3  # Leak conductance (mS/cm^2)\n",
       "\n",
       "# Gating Variables (HH Model Activation & Inactivation Functions)\n",
       "def alpha_n(V): return 0.01 * (V + 55) / (1 - np.exp(-(V + 55) / 10))\n",
       "def beta_n(V): return 0.125 * np.exp(-(V + 65) / 80)\n",
       "def alpha_m(V): return 0.1 * (V + 40) / (1 - np.exp(-(V + 40) / 10))\n",
       "def beta_m(V): return 4 * np.exp(-(V + 65) / 18)\n",
       "def alpha_h(V): return 0.07 * np.exp(-(V + 65) / 20)\n",
       "def beta_h(V): return 1 / (1 + np.exp(-(V + 35) / 10))\n",
       "\n",
       "# Hodgkin-Huxley Model Function\n",
       "def hh_model(I_ext, T=250, dt=0.01):\n",
       "    t = np.arange(0, T, dt)\n",
       "    V = np.full_like(t, V_rest)\n",
       "    n = 0.3177  # Initial value from steady state\n",
       "    m = 0.0529\n",
       "    h = 0.5961\n",
       "    I = np.zeros_like(t)\n",
       "    I[5000:15000] = I_ext  # Apply stimulus between 50ms and 150ms\n",
       "    \n",
       "    for i in range(1, len(t)):\n",
       "        # Update gating variables\n",
       "        dn = (alpha_n(V[i-1]) * (1 - n) - beta_n(V[i-1]) * n) * dt\n",
       "        dm = (alpha_m(V[i-1]) * (1 - m) - beta_m(V[i-1]) * m) * dt\n",
       "        dh = (alpha_h(V[i-1]) * (1 - h) - beta_h(V[i-1]) * h) * dt\n",
       "        \n",
       "        n += dn\n",
       "        m += dm\n",
       "        h += dh\n",
       "        \n",
       "        # Compute ionic currents\n",
       "        I_Na = G_Na * m**3 * h * (V[i-1] - E_Na)\n",
       "        I_K = G_K * n**4 * (V[i-1] - E_K)\n",
       "        I_L = G_L * (V[i-1] - E_L)\n",
       "        \n",
       "        # Membrane voltage update\n",
       "        dV = (I[i] - (I_Na + I_K + I_L)) / C_m * dt\n",
       "        V[i] = V[i-1] + dV\n",
       "    \n",
       "    return t, V, I\n",
       "\n",
       "# Simulating HH model with different input currents\n",
       "I_ext1 = 5.0  # Lower external current (not enough to trigger multiple spikes)\n",
       "I_ext2 = 15.0  # Stronger burst input\n",
       "\n",
       "t_hh1, V_hh1, I_hh1 = hh_model(I_ext1)\n",
       "t_hh2, V_hh2, I_hh2 = hh_model(I_ext2)\n",
       "\n",
       "# Plot Results\n",
       "plt.figure(figsize=(10, 6))\n",
       "\n",
       "# HH Model Membrane Potential for different inputs\n",
       "plt.subplot(2, 1, 1)\n",
       "plt.plot(t_hh1, V_hh1, label='Lower Input (5 uA/cm^2)', color='blue')\n",
       "plt.plot(t_hh2, V_hh2, label='Burst Input (15 uA/cm^2)', color='orange')\n",
       "plt.axhline(y=-55, color='r', linestyle='--', label=\"Threshold (-55 mV)\")\n",
       "plt.axhline(y=V_rest, color='g', linestyle='--', label=\"Resting Potential (-65 mV)\")\n",
       "plt.title('Hodgkin-Huxley Model with Different Inputs')\n",
       "plt.xlabel('Simulation Time (milliseconds)')\n",
       "plt.ylabel('Membrane Potential (mV)')\n",
       "plt.legend()\n",
       "\n",
       "# Stimulus Current Plot\n",
       "plt.subplot(2, 1, 2)\n",
       "plt.plot(t_hh1, I_hh1, label='Lower Input', color='blue', linestyle='--')\n",
       "plt.plot(t_hh2, I_hh2, label='Burst Input', color='orange', linestyle='--')\n",
       "plt.xlabel('Simulation Time (milliseconds)')\n",
       "plt.ylabel('Stimulus (uA/cm^2)')\n",
       "plt.legend()\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()\n",
       "\n",
       "# Explanation of Changes\n",
       "print(\"\\nExplanation:\")\n",
       "print(\"- The input current was modified from 10 uA/cm^2 to 5 uA/cm^2 (lower input) and 15 uA/cm^2 (burst input).\")\n",
       "print(\"- The lower input did not reach the threshold enough times to trigger repeated spikes, leading to fewer action potentials.\")\n",
       "print(\"- The burst input provided a stronger stimulus, causing more frequent and sustained spikes, mimicking real neuronal burst firing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff_model",
   "metadata": {},
   "outputs": [],
   "source": [
           "# simple_feedforward_nn.ipynb\n"
           "\n"
           "# Step 1: Import necessary libraries\n"
           "import numpy as np\n"
           "import matplotlib.pyplot as plt\n"
           "from sklearn.model_selection import train_test_split\n"
           "from sklearn.neural_network import MLPClassifier  # For classification\n"
           "from sklearn.metrics import accuracy_score\n"
           "\n"
           "# Step 2: Generate random data for a classification task\n"
           "def generate_sample_data(num_samples=1000, num_features=5):\n"
           '    """\n'
           '    Generates random data for a classification task.\n'
           '    \n'
           '    :param num_samples: int, number of samples to generate\n'
           '    :param num_features: int, number of input features\n'
           '    :return: tuple (X, y) where X is the input data and y is the target labels\n'
           '    """\n'
           "    X = np.random.rand(num_samples, num_features)  # Random features\n"
           "    y = np.random.randint(0, 2, size=(num_samples,))  # Random binary labels (0 or 1)\n"
           "    return X, y\n"
           "\n"
           "# Step 3: Split the data into training and testing sets\n"
           "X, y = generate_sample_data()\n"
           "\n"
           "# Split the data into training and testing sets (80% train, 20% test)\n"
           "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
           "\n"
           "# Step 4: Train model in stages and track accuracy\n"
           "def train_model_with_tracking(X_train, y_train, X_test, y_test, hidden_layer_sizes=(10,), max_iter=500):\n"
           '    """\n'
           '    Trains the neural network while tracking loss and accuracy at each iteration.\n'
           '    \n'
           '    :param X_train: Training input data\n'
           '    :param y_train: Training target labels\n'
           '    :param X_test: Testing input data\n'
           '    :param y_test: Testing target labels\n'
           '    :param hidden_layer_sizes: Tuple, number of neurons in each hidden layer\n'
           '    :param max_iter: Total number of training iterations\n'
           '    :return: Trained model, loss curve, accuracy curve\n'
           '    """\n'
           "    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, warm_start=True, max_iter=1, random_state=42)\n"
           "\n"
           "    loss_curve = []\n"
           "    accuracy_curve = []\n"
           "\n"
           "    for i in range(max_iter):\n"
           "        model.fit(X_train, y_train)  # Train for one iteration at a time\n"
           "        loss_curve.append(model.loss_)  # Store loss\n"
           "        y_train_pred = model.predict(X_train)\n"
           "        train_accuracy = accuracy_score(y_train, y_train_pred)  # Compute training accuracy\n"
           "        accuracy_curve.append(train_accuracy)  # Store accuracy\n"
           "\n"
           "    return model, loss_curve, accuracy_curve\n"
           "\n"
           "# Train model and track loss & accuracy\n"
           "model, loss_curve, accuracy_curve = train_model_with_tracking(X_train, y_train, X_test, y_test)\n"
           "\n"
           "# Step 5: Make predictions and evaluate the model\n"
           "y_pred = model.predict(X_test)\n"
           "test_accuracy = accuracy_score(y_test, y_pred)\n"
           "print(f\"Final Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
           "\n"
           "# Step 6: Plot Training Loss and Accuracy Curves\n"
           "plt.figure(figsize=(12, 5))\n"
           "\n"
           "# Loss Curve\n"
           "plt.subplot(1, 2, 1)\n"
           "plt.plot(loss_curve, label='Training Loss', color='blue')\n"
           "plt.title('Loss Curve during Training')\n"
           "plt.xlabel('Iterations')\n"
           "plt.ylabel('Loss')\n"
           "plt.legend()\n"
           "\n"
           "# Accuracy Curve\n"
           "plt.subplot(1, 2, 2)\n"
           "plt.plot(accuracy_curve, label='Training Accuracy', color='green')\n"
           "plt.axhline(y=test_accuracy, color='r', linestyle='--', label='Final Test Accuracy')\n"
           "plt.title('Training Accuracy Curve')\n"
           "plt.xlabel('Iterations')\n"
           "plt.ylabel('Accuracy')\n"
           "plt.legend()\n"
           "\n"
           "plt.tight_layout()\n"
           "plt.show()\n"
           "\n"
           "# Step 7: Make some sample predictions on the test set\n"
           "print(\"Predictions for the first 5 test samples:\")\n"
           "print(y_pred[:5])\n"
 ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Model Comparison\n",
    "IF models are one of the simplest neuron models. They integrate synaptic currents and fire a spike once the membrane potential reaches a predefined threshold, after which they reset. The IF model does not account for natural leakage of current across the membrane (leaky ion channels), and neurons in this model do not have a refractory period. Also in the IF model, membrane potential increases linearly and does not decay overtime. However, the LIF model has a nonlinear relationship between current and voltage. The LIF model is quite similar to the IF model, but it contains leaky ion channels, which allow for the membrane potential to exhibit a more natural decay. Some limitations of this model include that it requires an artificial spike generator to initiate action potentials, and it is missing the opening and closing of voltage-gated ion channels. A simple feedforward neural network (FNN) has the ability to learn and adapt, unlike IF/LIF models, and responds directly to inputs. However, this model has issues with making predictions and responding to novel situations. This system contains an actuator, which does the actual output action, and a controller, which provides the instructions for the actuator. One benefit of this model is that if the controller has good instructions, this model can respond both very quickly AND accurately. The LIF model contains more information than the IF model due to the inclusion of leaky channels, while the IF model is more binary and concise. The FNN, being the most complex, stores the most bits over time, making it the model with the greatest information content."
   ]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Differing Inputs\n",
    "The plots below illustrate the firing patterns if the inputs given differ. The input current patterns are modified in this Hodgkin-Huxley model to illustrate the different types of stimuli that affect neuronal firing. In the previous model a single, constant input current was applied for a period of time between 50ms to 150ms. This was replaced with two other input patterns: a weak, subthreshold input (3.0 uA/cmÂ²) that is continuous over the same time block and a burst input (15.0 uA/cmÂ²) that is added in short pulses at separate intervals of 50-60ms, 80-90ms, and 110-120ms. This results in differences in the membrane potential. The subthreshold input did not generate action potentials because it did not reach the threshold, however, the burst input had several spikes, because it depolarized to trigger an action potential. In the stimulus current graph, the weak input is a smooth, continuous signal, while the burst input showed distinct, intermittent peaks.\n",
    "![HH Model Results](graph2.png)\n"
   ]
  },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Inhibitory Inputs\n",
    "The plots below illustrate the firing patterns if inhibitory inputs are added on to the model. The solid blue line represents the neuron receiving only excitatory input, leading to action potential spikes. The dashed red line represents the neuron receiving both excitatory and inhibitory inputs, where inhibition suppresses the spikes. The second plot shows the input current patterns where the inhibitory input is overlapping with excitatory inputs, which counteracts its effect. This shows how the inhibitory inputs are reducing spikes.\n",
    "![HH Model Results](hhmodel2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend Your Knowledge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
