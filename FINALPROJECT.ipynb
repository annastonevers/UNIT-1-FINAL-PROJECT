{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Submission for Unit 1 Project\n",
    "#### Group 8: Annaston Evers, Juliette Vasquez, Madison Gaines, Mrityunjay Sivakumar, Shirley Lin, Uday Thakar, Victor Irby\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code and Resulting Visualization\n",
    "Below is the Python code for the following models:\n",
    "1. **Integrate and Fire (IF) Neuron Model**\n",
    "2. **Leaky Integrate and Fire (LIF) Model**\n",
    "3. **Simple Feedforward Neural Network (FNN)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate and Fire Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Parameters\n",
                "V_rest = -65  # Resting potential (mV)\n",
                "V_th = -55    # Threshold potential (mV)\n",
                "V_reset = V_rest  # Reset potential after firing (mV)\n",
                "tau = 20  # Membrane time constant (ms)\n",
                "R = 10  # Membrane resistance (MΩ)\n",
                "dt = 0.1  # Time step (ms)\n",
                "T = 100  # Total time for the simulation (ms)\n",
                "\n",
                "# Function to simulate the pure integrate-and-fire model\n",
                "def integrate_and_fire(I_ext, T=100, dt=0.1):\n",
                "    # Initialize time and membrane potential arrays\n",
                "    t = np.arange(0, T, dt)\n",
                "    V = np.full_like(t, V_rest)  # Membrane potential (initially resting potential)\n",
                "\n",
                "    # Iterate over each time step\n",
                "    for i in range(1, len(t)):\n",
                "        # Update membrane potential without decay\n",
                "        dV = (R * I_ext) * dt / tau  # No leak term\n",
                "        V[i] = V[i-1] + dV\n",
                "\n",
                "        # Check if the potential exceeds the threshold\n",
                "        if V[i] >= V_th:\n",
                "            V[i] = V_reset  # Reset after firing\n",
                "\n",
                "    return t, V\n",
                "\n",
                "# Simulate with different input currents\n",
                "I_ext_low = 1.5  # Low input current (nA)\n",
                "I_ext_high = 3.0  # High input current (nA)\n",
                "\n",
                "# Get results for both currents\n",
                "t_low, V_low = integrate_and_fire(I_ext_low)\n",
                "t_high, V_high = integrate_and_fire(I_ext_high)\n",
                "\n",
                "# Plotting the results\n",
                "plt.figure(figsize=(10, 6))\n",
                "\n",
                "# Low current input\n",
                "plt.subplot(2, 1, 1)\n",
                "plt.plot(t_low, V_low, label=f'I_ext = {I_ext_low} nA')\n",
                "plt.axhline(y=V_th, color='r', linestyle='--', label=\"Threshold (-55 mV)\")\n",
                "plt.axhline(y=V_rest, color='g', linestyle='--', label=\"Resting Potential (-65 mV)\")\n",
                "plt.title('Firing Pattern with Low Input Current')\n",
                "plt.xlabel('Time (ms)')\n",
                "plt.ylabel('Membrane Potential (mV)')\n",
                "plt.legend(loc='upper right')\n",
                "\n",
                "# High current input\n",
                "plt.subplot(2, 1, 2)\n",
                "plt.plot(t_high, V_high, label=f'I_ext = {I_ext_high} nA', color='orange')\n",
                "plt.axhline(y=V_th, color='r', linestyle='--', label=\"Threshold (-55 mV)\")\n",
                "plt.axhline(y=V_rest, color='g', linestyle='--', label=\"Resting Potential (-65 mV)\")\n",
                "plt.title('Firing Pattern with High Input Current')\n",
                "plt.xlabel('Time(ms)')\n",
                "plt.ylabel('Membrane Potential(mV)')\n",
                "plt.legend(loc='upper right')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n"
            ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IF Model Results](IFModelGraph.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky Integrate and Fire Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "V_rest = -65  # Resting potential (mV)\n",
    "V_th = -55    # Threshold potential (mV)\n",
    "V_reset = V_rest  # Reset potential after firing (mV)\n",
    "tau = 20  # Membrane time constant (ms)\n",
    "R = 10  # Membrane resistance (MΩ)\n",
    "dt = 0.1  # Time step (ms)\n",
    "T = 100  # Total time for the simulation (ms)\n",
    "\n",
    "# Function to simulate the integrate-and-fire model\n",
    "def integrate_and_fire(I_ext, T=100, dt=0.1):\n",
    "    # Initialize time and membrane potential arrays\n",
    "    t = np.arange(0, T, dt)\n",
    "    V = np.full_like(t, V_rest)  # Membrane potential (initially resting potential)\n",
    "\n",
    "    # Iterate over each time step\n",
    "    for i in range(1, len(t)):\n",
    "        # Differential equation for membrane potential (leaky part)\n",
    "        dV = (- (V[i-1] - V_rest) + R * I_ext) * dt / tau\n",
    "        V[i] = V[i-1] + dV\n",
    "\n",
    "        # Check if the potential exceeds the threshold\n",
    "        if V[i] >= V_th:\n",
    "            V[i] = V_reset  # Reset after firing\n",
    "\n",
    "    return t, V\n",
    "\n",
    "# Simulate with different input currents (e.g., 2 levels of input current)\n",
    "I_ext_low = 1.5  # Low input current (nA)\n",
    "I_ext_high = 3.0  # High input current (nA)\n",
    "\n",
    "# Get results for both currents\n",
    "t_low, V_low = integrate_and_fire(I_ext_low)\n",
    "t_high, V_high = integrate_and_fire(I_ext_high)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Low current input\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t_low, V_low, label=f'I_ext = {I_ext_low} nA')\n",
    "plt.axhline(y=V_th, color='r', linestyle='--', label='Threshold (-55 mV)')\n",
    "plt.axhline(y=V_rest, color='g', linestyle='--', label='Resting Potential (-65 mV)')\n",
    "plt.title('Firing Pattern with Low Input Current')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# High current input\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(t_high, V_high, label=f'I_ext = {I_ext_high} nA', color='orange')\n",
    "plt.axhline(y=V_th, color='r', linestyle='--', label='Threshold (-55 mV)')\n",
    "plt.axhline(y=V_rest, color='g', linestyle='--', label='Resting Potential (-65 mV)')\n",
    "plt.title('Firing Pattern with High Input Current')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
  ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LIF Model Results](LIFModelGraph.png)\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Feed-Forward Neural Network Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff_model",
   "metadata": {},
   "outputs": [],
   "source": [
		"# simple_feedforward_nn.ipynb\n",
"\n",
"# Step 1: Import necessary libraries\n",
"import numpy as np\n",
"import matplotlib.pyplot as plt\n",
"from sklearn.model_selection import train_test_split\n",
"from sklearn.neural_network import MLPClassifier  # For classification\n",
"from sklearn.metrics import accuracy_score\n",
"\n",
"# Step 2: Generate random data for a classification task\n",
"def generate_sample_data(num_samples=1000, num_features=5):\n",
"    \"\"\"\n",
"    Generates random data for a classification task.\n",
"    \n",
"    :param num_samples: int, number of samples to generate\n",
"    :param num_features: int, number of input features\n",
"    :return: tuple (X, y) where X is the input data and y is the target labels\n",
"    \"\"\"\n",
"    X = np.random.rand(num_samples, num_features)  # Random features\n",
"    y = np.random.randint(0, 2, size=(num_samples,))  # Random binary labels (0 or 1)\n",
"    return X, y\n",
"\n",
"# Step 3: Split the data into training and testing sets\n",
"X, y = generate_sample_data()\n",
"\n",
"# Split the data into training and testing sets (80% train, 20% test)\n",
"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
"\n",
"# Step 4: Train model in stages and track accuracy\n",
"def train_model_with_tracking(X_train, y_train, X_test, y_test, hidden_layer_sizes=(10,), max_iter=500):\n",
"    \"\"\"\n",
"    Trains the neural network while tracking loss and accuracy at each iteration.\n",
"    \n",
"    :param X_train: Training input data\n",
"    :param y_train: Training target labels\n",
"    :param X_test: Testing input data\n",
"    :param y_test: Testing target labels\n",
"    :param hidden_layer_sizes: Tuple, number of neurons in each hidden layer\n",
"    :param max_iter: Total number of training iterations\n",
"    :return: Trained model, loss curve, accuracy curve\n",
"    \"\"\"\n",
"    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, warm_start=True, max_iter=1, random_state=42)\n",
"    \n",
"    loss_curve = []\n",
"    accuracy_curve = []\n",
"    \n",
"    for i in range(max_iter):\n",
"        model.fit(X_train, y_train)  # Train for one iteration at a time\n",
"        loss_curve.append(model.loss_)  # Store loss\n",
"        y_train_pred = model.predict(X_train)\n",
"        train_accuracy = accuracy_score(y_train, y_train_pred)  # Compute training accuracy\n",
"        accuracy_curve.append(train_accuracy)  # Store accuracy\n",
"    \n",
"    return model, loss_curve, accuracy_curve\n",
"\n",
"# Train model and track loss & accuracy\n",
"model, loss_curve, accuracy_curve = train_model_with_tracking(X_train, y_train, X_test, y_test)\n",
"\n",
"# Step 5: Make predictions and evaluate the model\n",
"y_pred = model.predict(X_test)\n",
"test_accuracy = accuracy_score(y_test, y_pred)\n",
"print(f\"Final Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
"\n",
"# Step 6: Plot Training Loss and Accuracy Curves\n",
"plt.figure(figsize=(12, 5))\n",
"\n",
"# Loss Curve\n",
"plt.subplot(1, 2, 1)\n",
"plt.plot(loss_curve, label='Training Loss', color='blue')\n",
"plt.title('Loss Curve during Training')\n",
"plt.xlabel('Iterations')\n",
"plt.ylabel('Loss')\n",
"plt.legend()\n",
"\n",
"# Accuracy Curve\n",
"plt.subplot(1, 2, 2)\n",
"plt.plot(accuracy_curve, label='Training Accuracy', color='green')\n",
"plt.axhline(y=test_accuracy, color='r', linestyle='--', label='Final Test Accuracy')\n",
"plt.title('Training Accuracy Curve')\n",
"plt.xlabel('Iterations')\n",
"plt.ylabel('Accuracy')\n",
"plt.legend()\n",
"\n",
"plt.tight_layout()\n",
"plt.show()\n",
"\n",
"# Step 7: Make some sample predictions on the test set\n",
"print(\"Predictions for the first 5 test samples:\")\n",
"print(y_pred[:5])\n"
       ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FF Model Results](FFModelGraph.png)\n"
]
},
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Model Comparison\n",
    "IF models are one of the simplest neuron models. They integrate synaptic currents and fire a spike once the membrane potential reaches a predefined threshold, after which they reset. The IF model does not account for natural leakage of current across the membrane (leaky ion channels), and neurons in this model do not have a refractory period. Also in the IF model, membrane potential increases linearly and does not decay overtime. However, the LIF model has a nonlinear relationship between current and voltage. The LIF model is quite similar to the IF model, but it contains leaky ion channels, which allow for the membrane potential to exhibit a more natural decay. Some limitations of this model include that it requires an artificial spike generator to initiate action potentials, and it is missing the opening and closing of voltage-gated ion channels. A simple feedforward neural network (FNN) has the ability to learn and adapt, unlike IF/LIF models, and responds directly to inputs. However, this model has issues with making predictions and responding to novel situations. This system contains an actuator, which does the actual output action, and a controller, which provides the instructions for the actuator. One benefit of this model is that if the controller has good instructions, this model can respond both very quickly AND accurately. The LIF model contains more information than the IF model due to the inclusion of leaky channels, while the IF model is more binary and concise. The FNN, being the most complex, stores the most bits over time, making it the model with the greatest information content."
   ]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Differing Inputs\n",
    "The plots below illustrate the firing patterns if the inputs given differ. To simulate the HH model with different input currents, the code was updated from I_ext1 = 5.0 (input of external current at 5.0 uA), which is a lower external current (not enough to trigger multiple spikes), to I_ext2 = 15.0, which is a stronger burst input. The first scenario shown in blue has a weak input (5 uA/cm^2), that does not reach the threshold, so it results in no action potentials. The second scenario shown in orange features bursts of input (15 uA/cm^2) and this triggers multiple spikes in response to each burst. It demonstrates how input patterns affect neuronal firing and highlights the importance of stimulus intensity and timing.\n",
    "![HH Model Results](graph2.png)\n"
   ]
  },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Inhibitory Inputs\n",
    "The plots below illustrate the firing patterns if inhibitory inputs are added on to the model. To simulate the HH model with inhibitory inputs added in, the code was updated to first define input current patterns by added in an excitatory input from 50 ms to 150 ms, I_excitatory = [(50, 150, 10.0)], and adding in inhibitory input from 80ms to 120ms, I_inhibitory = [(80, 120, -5.0)]. The code also changes to simulate HH model with excitatory-only and excitatory+inhibitory inputs so the following lines of code are added in to simulate that: t_hh, V_hh_exc, I_hh_exc, _, I_total_exc = hh_model(I_excitatory, []) and t_hh, V_hh_inh, I_hh_exc, I_hh_inh, I_total_inh = hh_model(I_excitatory, I_inhibitory). These changes are reflected in the solid blue line found in the plot because it represents the neuron receiving only excitatory input, leading to action potential spikes. The dashed red line represents the neuron receiving both excitatory and inhibitory inputs, where inhibition suppresses the spikes. The second plot shows the input current patterns where the inhibitory input is overlapping with excitatory inputs, which counteracts its effect. This shows how the inhibitory inputs are reducing spikes.\n",
    "![HH Model Results](hhmodel2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend Your Knowledge - Coincidence Detection for Sound\n"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": ["**Intro to Coincidence Detection**\n"
]
},
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["Coincidence detection for sound localization relies on the ability of neurons to compare the timing of sound signals arriving from both ears.\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": ["**Mechanisms of Sound Localization**\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": ["To start off,\n",
	"**Delay lines**\n",
	"are neural pathways that transmit sound signals from each ear to specific postsynaptic neurons in the brainstem, such as those in the medial superior olive (MSO) (Franken et al., 2015). These delay lines have identical conduction velocities, meaning that the speed of action potentials is constant. Postsynaptic neurons only fire when they receive simultaneous input from both ears. This coincident input indicates that sound reached the neuron from both the left and right ears at the same time.\n",
	"For a neuron to fire, it must receive input from both ears at the same time. If only one ear detects the sound, no coincidence detection occurs, and no action potential is generated.\n",
	"The interaural time difference is the difference in arrival times of sound at each ear. helps the brain determine the direction of the sound source. When sound arrives at one ear before the other (because the sound source is closer to that ear), signals travel along the delay lines at slightly different times.\n",
	"If the sound source is closer to the left ear, the signal from the left ear reaches the delay line earlier than the signal from the right. The postsynaptic neuron that matches this timing difference will fire, indicating the sound's location.\n"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hearing](hearing1.png)\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
	"If the sound originates equally between both ears, signals from both ears travel equal distances and reach the central neuron simultaneously, resulting in zero interaural time difference.\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hearing](hearing1.png)\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the sound source is closer to the right ear, the signal travels a shorter distance along the right delay line and a longer distance along the left. A neuron that aligns with this timing difference will fire, encoding the interaural time difference and indicating the sound's direction.\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hearing](hearing1.png)\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": ["**Dynamic Refinement of ITD Detection**\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
	"While the foundational Jeffress model emphasized fixed anatomical structures like delay lines to explain ITD detection, recent research (Franken et al., 2015; Grothe et al., 2010) has revealed that the auditory system relies on\n",
	"**dynamic mechanisms**\n",
	"to refine coincidence detection. These mechanisms allow ITD processing to remain precise and adaptive even in challenging acoustic environments.\n"
   ]
}
]
 ,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
