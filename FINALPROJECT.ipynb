{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Submission for Unit 1 Project\n",
    "#### Group 8: Annaston Evers, Juliette Vasquez, Madison Gaines, Mrityunjay Sivakumar, Shirley Lin, Uday Thakar, Victor Irby\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code and Resulting Visualization\n",
    "Below is the Python code for the following models:\n",
    "1. **Integrate and Fire (IF) Neuron Model**\n",
    "2. **Leaky Integrate and Fire (LIF) Model**\n",
    "3. **Simple Feedforward Neural Network (FNN)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate and Fire Model\n"
   ]
  },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IF model is a simplified representation of a neuron and it describes how it integrates input currents and generates action potentials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Parameters\n",
                "V_rest = -65  # Resting potential (mV)\n",
                "V_th = -55    # Threshold potential (mV)\n",
                "V_reset = V_rest  # Reset potential after firing (mV)\n",
                "tau = 20  # Membrane time constant (ms)\n",
                "R = 10  # Membrane resistance (MΩ)\n",
                "dt = 0.1  # Time step (ms)\n",
                "T = 100  # Total time for the simulation (ms)\n",
                "\n",
                "# Function to simulate the pure integrate-and-fire model\n",
                "def integrate_and_fire(I_ext, T=100, dt=0.1):\n",
                "    # Initialize time and membrane potential arrays\n",
                "    t = np.arange(0, T, dt)\n",
                "    V = np.full_like(t, V_rest)  # Membrane potential (initially resting potential)\n",
                "\n",
                "    # Iterate over each time step\n",
                "    for i in range(1, len(t)):\n",
                "        # Update membrane potential without decay\n",
                "        dV = (R * I_ext) * dt / tau  # No leak term\n",
                "        V[i] = V[i-1] + dV\n",
                "\n",
                "        # Check if the potential exceeds the threshold\n",
                "        if V[i] >= V_th:\n",
                "            V[i] = V_reset  # Reset after firing\n",
                "\n",
                "    return t, V\n",
                "\n",
                "# Simulate with different input currents\n",
                "I_ext_low = 1.5  # Low input current (nA)\n",
                "I_ext_high = 3.0  # High input current (nA)\n",
                "\n",
                "# Get results for both currents\n",
                "t_low, V_low = integrate_and_fire(I_ext_low)\n",
                "t_high, V_high = integrate_and_fire(I_ext_high)\n",
                "\n",
                "# Plotting the results\n",
                "plt.figure(figsize=(10, 6))\n",
                "\n",
                "# Low current input\n",
                "plt.subplot(2, 1, 1)\n",
                "plt.plot(t_low, V_low, label=f'I_ext = {I_ext_low} nA')\n",
                "plt.axhline(y=V_th, color='r', linestyle='--', label=\"Threshold (-55 mV)\")\n",
                "plt.axhline(y=V_rest, color='g', linestyle='--', label=\"Resting Potential (-65 mV)\")\n",
                "plt.title('Firing Pattern with Low Input Current')\n",
                "plt.xlabel('Time (ms)')\n",
                "plt.ylabel('Membrane Potential (mV)')\n",
                "plt.legend(loc='upper right')\n",
                "\n",
                "# High current input\n",
                "plt.subplot(2, 1, 2)\n",
                "plt.plot(t_high, V_high, label=f'I_ext = {I_ext_high} nA', color='orange')\n",
                "plt.axhline(y=V_th, color='r', linestyle='--', label=\"Threshold (-55 mV)\")\n",
                "plt.axhline(y=V_rest, color='g', linestyle='--', label=\"Resting Potential (-65 mV)\")\n",
                "plt.title('Firing Pattern with High Input Current')\n",
                "plt.xlabel('Time(ms)')\n",
                "plt.ylabel('Membrane Potential(mV)')\n",
                "plt.legend(loc='upper right')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n"
            ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IF Model Results](IFModelGraph.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky Integrate and Fire Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code and Resulting Visualization\n",
    "Below is the Python code for the following models:\n",
    "1. **Integrate and Fire (IF) Neuron Model**\n",
    "2. **Leaky Integrate and Fire (LIF) Model**\n",
    "3. **Simple Feedforward Neural Network (FNN)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "V_rest = -65  # Resting potential (mV)\n",
    "V_th = -55    # Threshold potential (mV)\n",
    "V_reset = V_rest  # Reset potential after firing (mV)\n",
    "tau = 20  # Membrane time constant (ms)\n",
    "R = 10  # Membrane resistance (MΩ)\n",
    "dt = 0.1  # Time step (ms)\n",
    "T = 100  # Total time for the simulation (ms)\n",
    "\n",
    "# Function to simulate the integrate-and-fire model\n",
    "def integrate_and_fire(I_ext, T=100, dt=0.1):\n",
    "    # Initialize time and membrane potential arrays\n",
    "    t = np.arange(0, T, dt)\n",
    "    V = np.full_like(t, V_rest)  # Membrane potential (initially resting potential)\n",
    "\n",
    "    # Iterate over each time step\n",
    "    for i in range(1, len(t)):\n",
    "        # Differential equation for membrane potential (leaky part)\n",
    "        dV = (- (V[i-1] - V_rest) + R * I_ext) * dt / tau\n",
    "        V[i] = V[i-1] + dV\n",
    "\n",
    "        # Check if the potential exceeds the threshold\n",
    "        if V[i] >= V_th:\n",
    "            V[i] = V_reset  # Reset after firing\n",
    "\n",
    "    return t, V\n",
    "\n",
    "# Simulate with different input currents (e.g., 2 levels of input current)\n",
    "I_ext_low = 1.5  # Low input current (nA)\n",
    "I_ext_high = 3.0  # High input current (nA)\n",
    "\n",
    "# Get results for both currents\n",
    "t_low, V_low = integrate_and_fire(I_ext_low)\n",
    "t_high, V_high = integrate_and_fire(I_ext_high)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Low current input\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t_low, V_low, label=f'I_ext = {I_ext_low} nA')\n",
    "plt.axhline(y=V_th, color='r', linestyle='--', label='Threshold (-55 mV)')\n",
    "plt.axhline(y=V_rest, color='g', linestyle='--', label='Resting Potential (-65 mV)')\n",
    "plt.title('Firing Pattern with Low Input Current')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# High current input\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(t_high, V_high, label=f'I_ext = {I_ext_high} nA', color='orange')\n",
    "plt.axhline(y=V_th, color='r', linestyle='--', label='Threshold (-55 mV)')\n",
    "plt.axhline(y=V_rest, color='g', linestyle='--', label='Resting Potential (-65 mV)')\n",
    "plt.title('Firing Pattern with High Input Current')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
  ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LIF Model Results](LIFModelGraph.png)\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Feed-Forward Neural Network Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff_model",
   "metadata": {},
   "outputs": [],
   "source": [
	"import torch\n",
"import torch.nn as nn\n",
"import torch.optim as optim\n",
"import torch.nn.functional as F\n",
"import matplotlib.pyplot as plt\n",
"import numpy as np\n",
"\n",
"# Define a biologically relevant feed-forward neural network\n",
"class BioInspiredNN(nn.Module):\n",
"    def __init__(self, input_size, hidden_size, output_size):\n",
"        super(BioInspiredNN, self).__init__()\n",
"        \n",
"        # First layer with layer normalization (homeostatic regulation)\n",
"        self.fc1 = nn.Linear(input_size, hidden_size)\n",
"        self.bn1 = nn.LayerNorm(hidden_size)\n",
"        \n",
"        # Second layer with layer normalization\n",
"        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
"        self.bn2 = nn.LayerNorm(hidden_size)\n",
"        \n",
"        # Output layer\n",
"        self.fc3 = nn.Linear(hidden_size, output_size)\n",
"        \n",
"        # Leaky ReLU activation function to mimic neuronal thresholding\n",
"        self.leaky_relu = nn.LeakyReLU()\n",
"        \n",
"    def forward(self, x):\n",
"        x = self.leaky_relu(self.bn1(self.fc1(x)))\n",
"        x = self.leaky_relu(self.bn2(self.fc2(x)))\n",
"        x = torch.sigmoid(self.fc3(x))  # Sigmoid activation for output\n",
"        return x\n",
"\n",
"# Example usage\n",
"if __name__ == \"__main__\":\n",
"    # Define model parameters\n",
"    input_size = 10   # Number of input features\n",
"    hidden_size = 32  # Number of neurons in hidden layers\n",
"    output_size = 1   # Binary classification\n",
"    \n",
"    model = BioInspiredNN(input_size, hidden_size, output_size)\n",
"    model.eval()  # Ensure normalization does not require a larger batch size\n",
"    \n",
"    # Example input\n",
"    base_input = torch.rand((1, input_size))  # Initial input\n",
"    \n",
"    firing_rates = []\n",
"    time_steps = np.linspace(0, 10, 100)  # Simulated time steps\n",
"    spike_train = []\n",
"    \n",
"    for t in time_steps:\n",
"        # Gradually increase input over time to simulate synaptic potentiation\n",
"        sample_input = base_input + (t / 10.0)  # Increasing input over time\n",
"        output = model(sample_input.unsqueeze(0)).item()\n",
"        firing_rates.append(output)\n",
"        \n",
"        # Generate spikes based on threshold\n",
"        if output > np.random.rand():  # Probability-based spike occurrence\n",
"            spike_train.append(1)\n",
"        else:\n",
"            spike_train.append(0)\n",
"    \n",
"    # Plot the increasing firing rates over time\n",
"    plt.figure(figsize=(10, 5))\n",
"    plt.subplot(2, 1, 1)\n",
"    plt.plot(time_steps, firing_rates, label='Firing Rate')\n",
"    plt.xlabel('Time')\n",
"    plt.ylabel('Action Potential Firing Rate')\n",
"    plt.title('Increase in Firing Rate Over Time Due to Feed-Forward Mechanism')\n",
"    plt.legend()\n",
"    \n",
"    # Plot spike train\n",
"    plt.subplot(2, 1, 2)\n",
"    plt.eventplot([t for t, spike in zip(time_steps, spike_train) if spike], lineoffsets=1, colors='black')\n",
"    plt.xlabel('Time')\n",
"    plt.ylabel('Spikes')\n",
"    plt.title('Spike Train Over Time')\n",
"    \n",
"    plt.tight_layout()\n",
"    plt.show()\n"

       ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FF Model Results](FFModelGraph.png)\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Neural Network Visualization of Code Above\n"
   ]
  },
{
   "cell_type": "code",
   "execution_count": null,
   "id": "ff_model",
   "metadata": {},
   "outputs": [],
   "source": [
	"import networkx as nx\n",
	"import matplotlib.pyplot as plt\n",
	"\n",
	"# Define layers\n",
	"input_nodes = ['Input 1', 'Input 2', 'Input 3']\n",
	"hidden_nodes = ['Hidden 1', 'Hidden 2', 'Hidden 3', 'Hidden 4']\n",
	"output_nodes = ['Output 1', 'Output 2']\n",
	"\n",
	"# Create directed graph\n",
	"G = nx.DiGraph()\n",
	"\n",
	"# Add nodes\n",
	"G.add_nodes_from(input_nodes)\n",
	"G.add_nodes_from(hidden_nodes)\n",
	"G.add_nodes_from(output_nodes)\n",
	"\n",
	"# Fully connect input to hidden layer\n",
	"for i in input_nodes:\n",
	"    for h in hidden_nodes:\n",
	"        G.add_edge(i, h)\n",
	"\n",
	"# Fully connect hidden to output layer\n",
	"for h in hidden_nodes:\n",
	"    for o in output_nodes:\n",
	"        G.add_edge(h, o)\n",
	"\n",
	"# Define positions for better visualization\n",
	"pos = {}\n",
	"layer_distance = 1.5\n",
	"node_spacing = 1.0\n",
	"\n",
	"for i, node in enumerate(input_nodes):\n",
	"    pos[node] = (0, -i * node_spacing)\n",
	"\n",
	"for i, node in enumerate(hidden_nodes):\n",
	"    pos[node] = (layer_distance, -i * node_spacing)\n",
	"\n",
	"for i, node in enumerate(output_nodes):\n",
	"    pos[node] = (2 * layer_distance, -i * node_spacing)\n",
	"\n",
	"# Draw the network\n",
	"plt.figure(figsize=(8, 6))\n",
	"nx.draw(G, pos, with_labels=True, node_size=2000, node_color='lightblue', edge_color='gray', font_size=10, font_weight='bold', arrows=True)\n",
	"\n",
	"plt.title('Feedforward Neural Network Structure')\n",
	"plt.show()\n"

]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FF Model Visualization](FFModelVis.png)\n"
]
},
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Model Comparison\n",
    "IF models are one of the simplest neuron models. They integrate synaptic currents and fire a spike once the membrane potential reaches a predefined threshold, after which they reset. The IF model does not account for natural leakage of current across the membrane (leaky ion channels), and neurons in this model do not have a refractory period. Also in the IF model, membrane potential increases linearly and does not decay overtime. However, the LIF model has a nonlinear relationship between current and voltage. The LIF model is quite similar to the IF model, but it contains leaky ion channels, which allow for the membrane potential to exhibit a more natural decay. Some limitations of this model include that it requires an artificial spike generator to initiate action potentials, and it is missing the opening and closing of voltage-gated ion channels. A simple feedforward neural network (FNN) has the ability to learn and adapt, unlike IF/LIF models, and responds directly to inputs. However, this model has issues with making predictions and responding to novel situations. This system contains an actuator, which does the actual output action, and a controller, which provides the instructions for the actuator. One benefit of this model is that if the controller has good instructions, this model can respond both very quickly AND accurately. The LIF model contains more information than the IF model due to the inclusion of leaky channels, while the IF model is more binary and concise. The FNN, being the most complex, stores the most bits over time, making it the model with the greatest information content."
   ]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Differing Inputs\n",
    "The plots below illustrate the firing patterns if the inputs given differ. To simulate the HH model with different input currents, the code was updated from I_ext1 = 5.0 (input of external current at 5.0 uA), which is a lower external current (not enough to trigger multiple spikes), to I_ext2 = 15.0, which is a stronger burst input. The first scenario shown in blue has a weak input (5 uA/cm^2), that does not reach the threshold, so it results in no action potentials. The second scenario shown in orange features bursts of input (15 uA/cm^2) and this triggers multiple spikes in response to each burst. It demonstrates how input patterns affect neuronal firing and highlights the importance of stimulus intensity and timing.\n",
    "![HH Model Results](graph2.png)\n"
   ]
  },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Inhibitory Inputs\n",
    "The plots below illustrate the firing patterns if inhibitory inputs are added on to the model. To simulate the HH model with inhibitory inputs added in, the code was updated to first define input current patterns by added in an excitatory input from 50 ms to 150 ms, I_excitatory = [(50, 150, 10.0)], and adding in inhibitory input from 80ms to 120ms, I_inhibitory = [(80, 120, -5.0)]. The code also changes to simulate HH model with excitatory-only and excitatory+inhibitory inputs so the following lines of code are added in to simulate that: t_hh, V_hh_exc, I_hh_exc, _, I_total_exc = hh_model(I_excitatory, []) and t_hh, V_hh_inh, I_hh_exc, I_hh_inh, I_total_inh = hh_model(I_excitatory, I_inhibitory). These changes are reflected in the solid blue line found in the plot because it represents the neuron receiving only excitatory input, leading to action potential spikes. The dashed red line represents the neuron receiving both excitatory and inhibitory inputs, where inhibition suppresses the spikes. The second plot shows the input current patterns where the inhibitory input is overlapping with excitatory inputs, which counteracts its effect. This shows how the inhibitory inputs are reducing spikes.\n",
    "![HH Model Results](hhmodel2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend Your Knowledge - Coincidence Detection for Sound\n"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": ["**Intro to Coincidence Detection**\n"
]
},
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["Coincidence detection for sound localization relies on the ability of neurons to compare the timing of sound signals arriving from both ears.\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": ["**Mechanisms of Sound Localization**\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": ["To start off,\n",
	"**Delay lines**\n",
	"are neural pathways that transmit sound signals from each ear to specific postsynaptic neurons in the brainstem, such as those in the medial superior olive (MSO) (Franken et al., 2015). These delay lines have identical conduction velocities, meaning that the speed of action potentials is constant. Postsynaptic neurons only fire when they receive simultaneous input from both ears. This coincident input indicates that sound reached the neuron from both the left and right ears at the same time.\n",
	"For a neuron to fire, it must receive input from both ears at the same time. If only one ear detects the sound, no coincidence detection occurs, and no action potential is generated.\n",
	"The interaural time difference is the difference in arrival times of sound at each ear. helps the brain determine the direction of the sound source. When sound arrives at one ear before the other (because the sound source is closer to that ear), signals travel along the delay lines at slightly different times.\n",
	"If the sound source is closer to the left ear, the signal from the left ear reaches the delay line earlier than the signal from the right. The postsynaptic neuron that matches this timing difference will fire, indicating the sound's location.\n"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hearing](h1.png)\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
	"If the sound originates equally between both ears, signals from both ears travel equal distances and reach the central neuron simultaneously, resulting in zero interaural time difference.\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hearing](h2.png)\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the sound source is closer to the right ear, the signal travels a shorter distance along the right delay line and a longer distance along the left. A neuron that aligns with this timing difference will fire, encoding the interaural time difference and indicating the sound's direction.\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hearing](h3.png)\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": ["**Dynamic Refinement of ITD Detection**\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
	"While the foundational Jeffress model emphasized fixed anatomical structures like delay lines to explain ITD detection, recent research (Franken et al., 2015; Grothe et al., 2010) has revealed that the auditory system relies on\n",
	"**dynamic mechanisms**\n",
	"to refine coincidence detection. These mechanisms allow ITD processing to remain precise and adaptive even in challenging acoustic environments.\n",
	"Dynamic tuning of ITD detection is explained in part by the intrinsic electrical properties of MSO neurons. Specialized ion channels, such as Kv1 potassium channels, regulate the timing and threshold for action potentials. These channels can make sure that neurons only fire when inputs from both ears are precisely synchronized. Also, voltage-gated sodium channels modify spike probabilities based on preceding synaptic activity. Together, these ion channels create\n",
	"**phase delays**\n",
	"that refine ITD detection beyond the anatomical delays provided by fixed delay lines. The alignment of synaptic inputs arriving from each ear determines whether an MSO neuron will fire. Franken et al. (2015) demonstrated that preceding synaptic activity could dynamically shift the neuron’s sensitivity to timing differences, further influencing ITD tuning. This shows that coincidence detection involves more than just simple summation since it also incorporates the recent history of synaptic inputs.\n"

   ]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": ["**Frequency and Real-World Application**\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": ["ITD detection also depends on the frequency of the sound. Lower frequency, longer wavelength sound produces clearer timing differences, making ITDs the primary cue for localization. High frequency, shorter wavelength sound creates sound shadows, causing interaural level differences (ILDs; differences in sound intensity between the two ears) to become more prominent. The auditory system integrates both ITD and ILD cues for accurate localization across all frequencies (Grothe et al., 2010).\n",
	"Grothe et al. (2010) found that, unlike birds, mammals do not have a fixed spatial map of ITDs in their brainstem. In birds, the nucleus laminaris contains a structured arrangement of neurons, where each neuron is tuned to a specific ITD, effectively creating a 'map' of sound location. In contrast, mammals rely more on dynamic neuronal properties, such as adaptive changes in synaptic input timing and ion channel activity, to process ITDs rather than a spatial representation as suggested by the\n",
	"**Jeffress Model.**\n",
	"The dynamic adaptability of coincidence detection is greatly important for real-world sound localization scenarios, like the cocktail party effect. Dynamic ITD tuning allows people to focus on a single speaker in a noisy environment. Also, ITD cues can be combined with visual information to enhance your perception of space, especially in a noisy or ambiguous environment.\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": ["**A Dynamic System**\n"
]
},
{
   "cell_type": "markdown",
   "metadata": {},
   "source": ["Coincidence detection for sound localization is a lot more dynamic and adaptive than proposed by the Jeffress model, which is a good start for learning about how we localize sound. Integration of synaptic inputs, intrinsic neuronal properties, and frequency-dependent modifications ensure that the auditory system is effective in different acoustic environments. Findings from Franken et al. (2015) and Grothe et al. (2010) demonstrate how complex this process is, revealing how the auditory system combines anatomy with dynamic neural mechanisms to allow for spatial awareness.\n"
]
},
{
"cell_type": "markdown",
   "metadata": {},
   "source": ["You can read more about these findings from:\n"
]
},
{
"cell_type": "markdown",
   "metadata": {},
   "source": ["Franken et al. (2015)\n",
	"[https://pmc.ncbi.nlm.nih.gov/articles/PMC4410695/](https://pmc.ncbi.nlm.nih.gov/articles/PMC4410695/)\n"
]
},
{
"cell_type": "markdown",
   "metadata": {},
   "source": ["and Grothe et al. (2010)\n",
	"[https://journals.physiology.org/doi/full/10.1152/physrev.00026.2009](https://journals.physiology.org/doi/full/10.1152/physrev.00026.2009)\n"
]
}
],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
