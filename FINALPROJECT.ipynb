{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Submission for Unit 1 Project\n",
    "#### Group 8: Annaston Evers, Juliette Vasquez, Madison Gaines, Mrityunjay Sivakumar, Shirley Lin, Uday Thakar, Victor Irby\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code and Resulting Visualization\n",
    "Below is the Python code for the following models:\n",
    "1. **Integrate and Fire (IF) Neuron Model**\n",
    "2. **Leaky Integrate and Fire (LIF) Model**\n",
    "3. **Simple Feedforward Neural Network (FNN)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "if_model",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lif_model",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffnn_model",
   "metadata": {},
   "outputs": [],
   "source": [
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Generate sample data
# For this example, we're creating random data for demonstration
X = np.random.rand(100, 5)  # 100 samples with 5 features each
y = np.random.randint(0, 2, size=(100, 1))  # Binary target (0 or 1)

# Define the feed-forward neural network model
model = Sequential()

# Input layer with 5 input features and a hidden layer of 10 neurons
model.add(Dense(10, input_dim=5, activation='relu'))  # Hidden layer with 10 neurons

# Output layer for binary classification (1 neuron with sigmoid activation)
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X, y, epochs=50, batch_size=10)

# Test the model on the same input data
predictions = model.predict(X)

# Print first 5 predictions
print(predictions[:5])

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Model Comparison\n",
    "IF models are one of the simplest neuron models. They integrate synaptic currents and fire a spike once the membrane potential reaches a predefined threshold, after which they reset. These models lack a refractory period of a biological neuron, as well as other characteristics such as leakage and adaptation. LIF models improve upon this by incorporating a leak in the membrane potential, meaning that if no input is received, the potential will gradually return to its resting state. This model is more biologically accurate but still lacks a refractory period and ion channel dynamics. A simple feedforward neural network (FNN) has the ability to learn and adapt, unlike IF/LIF models, and responds directly to inputs. However, it is more difficult to make predictions compared to other biologically inspired models. The LIF model contains more information than the IF model due to the inclusion of the leak, while the IF model is more binary and concise. The FNN, being the most complex, stores the most bits over time, making it the model with the greatest information content."
   ]
},
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
